{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "L4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<a href=\"https://colab.research.google.com/github/https://github.com/BhaskarS1ngha/ICPR_LEAF_INSPECT_CHALLENGE/blob/master/Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DEFINE SOURCE DIRECTORIES"
   ],
   "metadata": {
    "id": "9caM761tZzgp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "SOURCE_DIRECTORY = \"Test_data\"\n",
    "MODEL_DIRECTORY = \"mask2former-swin-large-leaf\"\n",
    "results_dir = \"results\""
   ],
   "metadata": {
    "id": "zYxzTwORZzLa"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# INSTALL DEPENDENCIES"
   ],
   "metadata": {
    "id": "qpw475RkaHOk"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4J0TRl9luQF6",
    "outputId": "0710cb35-a6a8-4c7d-e491-874a58a6d3a1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers albumentations opencv-python datasets==2.15\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# LOAD INFERENCE DATA"
   ],
   "metadata": {
    "id": "G3a2qS9taKem"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "images = os.listdir(SOURCE_DIRECTORY)\n",
    "\n",
    "#filter images with .png extension\n",
    "images = [img for img in images if img.split('.')[-1] == 'png']\n",
    "\n",
    "\n",
    "\n",
    "print('Total images:', len(images))\n",
    "\n",
    "\n",
    "# create dataframe with columns img_no, label, img_path, mask_path\n",
    "df = pd.DataFrame(columns=['img_no', 'img_path'])\n",
    "imgNo = 0\n",
    "for i in range(len(images)):\n",
    "    img_path = os.path.join(SOURCE_DIRECTORY, images[i])\n",
    "    tempDict = {'img_no': imgNo,\n",
    "                'img_path': img_path}\n",
    "    df = pd.concat([df, pd.DataFrame([tempDict])], ignore_index=True)\n",
    "    imgNo += 1\n",
    "\n",
    "#set index to img_no\n",
    "df.set_index('img_no', inplace=True)\n",
    "df.to_csv(\"dataset_validation.csv\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lrJ689AjvPrU",
    "outputId": "0c3b42a9-60f7-4a74-b535-e44642c6f777"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import datasets\n",
    "\n",
    "dataset_csv = \"dataset_validation.csv\"\n",
    "dataset_df = pd.read_csv(dataset_csv)\n",
    "dataset_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4qWsv4T5vTf5",
    "outputId": "0f08f6a6-6bb1-4e75-9a97-d1243307e505"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset_df['img_name'] = dataset_df['img_path'].apply(lambda x: x.split(os.sep)[-1])\n",
    "dataset_df.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MG1Y-g2Wvcmd",
    "outputId": "f120bdd2-5f8f-442c-9e7e-e06e49b5c844"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "IMAGES = dataset_df['img_path']\n",
    "IMG_NAMES = dataset_df['img_name']\n",
    "for i in range(len(IMAGES)):\n",
    "    if not os.path.exists(IMAGES[i]):\n",
    "        print(f\"Image: {IMAGES[i]} does not exist\")\n",
    "        raise FileNotFoundError(\"Image does not exist\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 913
    },
    "id": "O3Mk5EvkztnW",
    "outputId": "78436027-e915-4bdb-8b00-179ca2adbfd3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset = datasets.Dataset.from_dict({\"pixel_values\": IMAGES}, features=datasets.Features({\"pixel_values\": datasets.Image()}))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = dataset.add_column(\"img_name\", IMG_NAMES)\n",
    "dataset"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QjBXxWknwJVY",
    "outputId": "4467def8-5d39-452d-b1ca-862da703f984"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset[0]['pixel_values']"
   ],
   "metadata": {
    "id": "kQXUPWg4w0rD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# INFERENCE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import Mask2FormerForUniversalSegmentation\n",
    "from transformers import MaskFormerImageProcessor\n",
    "import torch\n",
    "\n",
    "id2label = {0: \"leaf\"}\n",
    "label2id = {\"leaf\": 0}\n",
    "model = Mask2FormerForUniversalSegmentation.from_pretrained(MODEL_DIRECTORY, id2label=id2label, label2id=label2id, ignore_mismatched_sizes=True)\n",
    "processor = MaskFormerImageProcessor()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "if not os.path.exists(results_dir):\n",
    "    os.mkdir(results_dir)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VbY-5_gwofS",
    "outputId": "85e53a16-221c-48c6-cc9c-93bf54cc4d24"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from PIL import Image\n",
    "def get_mask(segmentation, segment_id):\n",
    "  mask = (segmentation.cpu().numpy() == segment_id)\n",
    "  visual_mask = (mask * (segment_id+1)).astype(np.uint8)\n",
    "  visual_mask = Image.fromarray(visual_mask)\n",
    "\n",
    "  return visual_mask"
   ],
   "metadata": {
    "id": "h8lHZ0tjxZFh"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GENERATE OUTPUT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_imgs = len(dataset)\n",
    "print(f\"Processing {n_imgs} images\")\n",
    "for i in range(len(dataset)):\n",
    "    image = dataset[i][\"pixel_values\"]\n",
    "    img_name = dataset[i][\"img_name\"]\n",
    "    print(f\"Processing {i}/{n_imgs}: {img_name}\")\n",
    "    inputs = processor(image, return_tensors=\"pt\").to(device)\n",
    "    for k,v in inputs.items():\n",
    "      print(k,v.shape)\n",
    "    with torch.no_grad():\n",
    "      outputs = model(**inputs)\n",
    "    results = processor.post_process_instance_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "    print(results.keys())\n",
    "    fmask = None\n",
    "    for segment in results['segments_info']:\n",
    "        # print(\"Visualizing mask for instance:\", model.config.id2label[segment['label_id']])\n",
    "        mask = get_mask(results['segmentation'], segment['id'])\n",
    "        if fmask is None:\n",
    "          fmask = np.array(mask)\n",
    "        fmask = cv.bitwise_or(fmask, np.array(mask))\n",
    "        # display(mask)\n",
    "    outPath = os.path.join(results_dir, img_name)\n",
    "    cv.imwrite(outPath, fmask)\n",
    "    print(f\"Saved mask to {outPath}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
